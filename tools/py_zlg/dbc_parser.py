#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
DBCæ–‡ä»¶è§£æå™¨
æ”¯æŒCANæ•°æ®åº“æ–‡ä»¶è§£æï¼Œæå–ä¿¡å·å®šä¹‰ä¿¡æ¯
"""

import re
import os
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

@dataclass
class DBCSignal:
    """DBCä¿¡å·å®šä¹‰"""
    name: str
    start_bit: int
    length: int
    byte_order: str  # 'big_endian' or 'little_endian'
    value_type: str  # 'signed' or 'unsigned'
    factor: float
    offset: float
    minimum: float
    maximum: float
    unit: str
    receivers: List[str]
    comment: str = ""
    value_table: Dict[int, str] = None

@dataclass
class DBCMessage:
    """DBCæ¶ˆæ¯å®šä¹‰"""
    can_id: int
    name: str
    dlc: int
    transmitter: str
    signals: List[DBCSignal]
    comment: str = ""
    cycle_time: int = 0  # å‘¨æœŸæ—¶é—´(ms)
    is_extended: bool = False  # æ˜¯å¦ä¸ºæ‰©å±•å¸§

@dataclass
class DBCNode:
    """DBCèŠ‚ç‚¹å®šä¹‰"""
    name: str
    comment: str = ""

class DBCParser:
    """DBCæ–‡ä»¶è§£æå™¨"""
    
    # æ‰©å±•å¸§æ ‡è®°ä½ï¼ˆDBC æ–‡ä»¶ä¸­æ‰©å±•å¸§ ID = å®é™…ID + 0x80000000ï¼‰
    EXTENDED_FRAME_FLAG = 0x80000000
    
    def __init__(self):
        self.nodes: List[DBCNode] = []
        self.messages: List[DBCMessage] = []
        self.value_tables: Dict[str, Dict[int, str]] = {}
        self.attributes: Dict[str, Any] = {}
        self.comments: Dict[str, str] = {}
    
    @staticmethod
    def _convert_raw_can_id(raw_id: int) -> tuple:
        """
        è½¬æ¢åŸå§‹ CAN ID ä¸ºå®é™… ID å’Œæ‰©å±•å¸§æ ‡è®°
        
        DBC æ–‡ä»¶ä¸­æ‰©å±•å¸§çš„ä¸¤ç§ç¼–ç æ–¹å¼ï¼š
        1. æ ‡å‡†æ–¹å¼ï¼šactual_id + 0x80000000
        2. ç®€åŒ–æ–¹å¼ï¼šç›´æ¥å†™ actual_idï¼ˆæŸäº›å·¥å…·ï¼‰
        
        æ ‡å‡†å¸§èŒƒå›´ï¼š0x000 - 0x7FF (0-2047)
        æ‰©å±•å¸§èŒƒå›´ï¼š0x000 - 0x1FFFFFFF (0-536870911)
        
        Args:
            raw_id: DBC æ–‡ä»¶ä¸­çš„åŸå§‹ CAN ID
            
        Returns:
            (actual_id, is_extended): å®é™… CAN ID å’Œæ˜¯å¦ä¸ºæ‰©å±•å¸§
        """
        if raw_id >= DBCParser.EXTENDED_FRAME_FLAG:
            # æ ‡å‡†æ‰©å±•å¸§ç¼–ç ï¼šID + 0x80000000
            is_extended = True
            actual_id = raw_id - DBCParser.EXTENDED_FRAME_FLAG
        elif raw_id > 0x7FF:
            # ç®€åŒ–æ‰©å±•å¸§ç¼–ç ï¼šç›´æ¥å†™å®é™… IDï¼ˆè¶…è¿‡æ ‡å‡†å¸§èŒƒå›´è§†ä¸ºæ‰©å±•å¸§ï¼‰
            is_extended = True
            actual_id = raw_id
        else:
            # æ ‡å‡†å¸§ï¼š0x000 - 0x7FF
            is_extended = False
            actual_id = raw_id
        
        return actual_id, is_extended
    
    def parse_file(self, file_path: str) -> bool:
        """
        è§£æDBCæ–‡ä»¶
        
        Args:
            file_path: DBCæ–‡ä»¶è·¯å¾„
            
        Returns:
            è§£ææ˜¯å¦æˆåŠŸ
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"DBCæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        print(f"ğŸ“ è§£æDBCæ–‡ä»¶: {file_path}")
        
        try:
            # æ£€æµ‹ç¼–ç 
            encoding = self._detect_encoding(file_path)
            print(f"ğŸ”¤ æ£€æµ‹ç¼–ç : {encoding}")
            
            # è¯»å–æ–‡ä»¶
            with open(file_path, 'r', encoding=encoding) as f:
                content = f.read()
            
            # æ¸…ç©ºä¹‹å‰çš„æ•°æ®
            self.nodes.clear()
            self.messages.clear()
            self.value_tables.clear()
            self.attributes.clear()
            self.comments.clear()
            
            # è§£æå„ä¸ªéƒ¨åˆ†
            self._parse_nodes(content)
            self._parse_value_tables(content)
            self._parse_messages(content)
            self._parse_comments(content)
            self._parse_attributes(content)
            
            print(f"âœ… DBCè§£æå®Œæˆ:")
            print(f"   èŠ‚ç‚¹æ•°: {len(self.nodes)}")
            print(f"   æ¶ˆæ¯æ•°: {len(self.messages)}")
            print(f"   ä¿¡å·æ•°: {sum(len(msg.signals) for msg in self.messages)}")
            
            return True
            
        except Exception as e:
            print(f"âŒ DBCè§£æå¤±è´¥: {e}")
            return False
    
    def _detect_encoding(self, file_path: str) -> str:
        """æ£€æµ‹æ–‡ä»¶ç¼–ç """
        encodings = ['utf-8', 'gbk', 'ascii', 'latin1']
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    f.read()
                return encoding
            except UnicodeDecodeError:
                continue
        
        return 'utf-8'  # é»˜è®¤
    
    def _parse_nodes(self, content: str):
        """è§£æèŠ‚ç‚¹å®šä¹‰"""
        # BU_: Node1 Node2 Node3
        pattern = r'BU_:\s*(.*?)(?:\n|$)'
        match = re.search(pattern, content, re.MULTILINE)
        
        if match:
            nodes_line = match.group(1).strip()
            if nodes_line:
                node_names = nodes_line.split()
                for name in node_names:
                    self.nodes.append(DBCNode(name=name))
    
    def _parse_value_tables(self, content: str):
        """è§£æå€¼è¡¨å®šä¹‰"""
        # VAL_TABLE_ TableName 0 "Value0" 1 "Value1" ;
        pattern = r'VAL_TABLE_\s+(\w+)\s+((?:\d+\s+"[^"]*"\s*)*);'
        
        for match in re.finditer(pattern, content, re.MULTILINE):
            table_name = match.group(1)
            values_str = match.group(2)
            
            # è§£æå€¼å¯¹
            value_pattern = r'(\d+)\s+"([^"]*)"'
            values = {}
            for value_match in re.finditer(value_pattern, values_str):
                key = int(value_match.group(1))
                value = value_match.group(2)
                values[key] = value
            
            self.value_tables[table_name] = values
    
    def _parse_messages(self, content: str):
        """è§£ææ¶ˆæ¯å’Œä¿¡å·å®šä¹‰"""
        # BO_ 123 MessageName: 8 NodeName
        message_pattern = r'BO_\s+(\d+)\s+(\w+):\s*(\d+)\s+(\w+)'
        
        for msg_match in re.finditer(message_pattern, content, re.MULTILINE):
            can_id_raw = int(msg_match.group(1))
            msg_name = msg_match.group(2)
            dlc = int(msg_match.group(3))
            transmitter = msg_match.group(4)
            
            # è¿‡æ»¤ç‰¹æ®Šæ¶ˆæ¯ï¼šVECTOR__INDEPENDENT_SIG_MSG (ç”¨äºæœªç»‘å®šçš„ç‹¬ç«‹ä¿¡å·)
            # è¿™ç±»æ¶ˆæ¯çš„ ID é€šå¸¸æ˜¯ 0xC0000000 (3221225472) æˆ–å…¶ä»–è¶…å‡ºèŒƒå›´çš„å€¼
            if 'INDEPENDENT_SIG_MSG' in msg_name or can_id_raw >= 0xC0000000:
                continue
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºæ‰©å±•å¸§å¹¶æå–å®é™…çš„ CAN ID
            can_id, is_extended = self._convert_raw_can_id(can_id_raw)
            
            # è¿‡æ»¤æ— æ•ˆçš„æ‰©å±•å¸§ IDï¼ˆè¶…å‡ºæ‰©å±•å¸§æœ€å¤§èŒƒå›´ 0x1FFFFFFFï¼‰
            if is_extended and can_id > 0x1FFFFFFF:
                continue
            
            # æŸ¥æ‰¾è¯¥æ¶ˆæ¯çš„æ‰€æœ‰ä¿¡å·
            signals = self._parse_signals_for_message(content, msg_match.end())
            
            message = DBCMessage(
                can_id=can_id,
                name=msg_name,
                dlc=dlc,
                transmitter=transmitter,
                signals=signals,
                is_extended=is_extended
            )
            
            self.messages.append(message)
    
    def _parse_signals_for_message(self, content: str, start_pos: int) -> List[DBCSignal]:
        """è§£ææ¶ˆæ¯çš„ä¿¡å·å®šä¹‰"""
        signals = []
        
        # ä»æ¶ˆæ¯å®šä¹‰åå¼€å§‹æŸ¥æ‰¾ä¿¡å·ï¼Œç›´åˆ°ä¸‹ä¸€ä¸ªæ¶ˆæ¯å®šä¹‰
        remaining_content = content[start_pos:]
        
        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªBO_å®šä¹‰çš„ä½ç½®ï¼Œé™åˆ¶æœç´¢èŒƒå›´
        next_msg_match = re.search(r'\nBO_', remaining_content)
        if next_msg_match:
            search_content = remaining_content[:next_msg_match.start()]
        else:
            search_content = remaining_content
        
        # SG_ SignalName : 0|8@1+ (1,0) [0|255] "unit" Receiver1,Receiver2
        signal_pattern = r'SG_\s+(\w+)\s*:\s*(\d+)\|(\d+)@([01])([+-])\s*\(([^,]+),([^)]+)\)\s*\[([^|]*)\|([^\]]*)\]\s*"([^"]*)"\s*([^\n]*)'
        
        for signal_match in re.finditer(signal_pattern, search_content, re.MULTILINE):
            signal_name = signal_match.group(1)
            start_bit = int(signal_match.group(2))
            length = int(signal_match.group(3))
            byte_order = 'little_endian' if signal_match.group(4) == '1' else 'big_endian'
            value_type = 'signed' if signal_match.group(5) == '-' else 'unsigned'
            factor = float(signal_match.group(6))
            offset = float(signal_match.group(7))
            minimum = float(signal_match.group(8)) if signal_match.group(8).strip() else 0.0
            maximum = float(signal_match.group(9)) if signal_match.group(9).strip() else 0.0
            unit = signal_match.group(10)
            receivers_str = signal_match.group(11).strip()
            receivers = [r.strip() for r in receivers_str.split(',') if r.strip()]
            
            signal = DBCSignal(
                name=signal_name,
                start_bit=start_bit,
                length=length,
                byte_order=byte_order,
                value_type=value_type,
                factor=factor,
                offset=offset,
                minimum=minimum,
                maximum=maximum,
                unit=unit,
                receivers=receivers
            )
            
            signals.append(signal)
        
        return signals
    
    def _parse_comments(self, content: str):
        """è§£ææ³¨é‡Š"""
        # CM_ "comment text";
        # CM_ BU_ NodeName "comment text";
        # CM_ BO_ 123 "comment text";
        # CM_ SG_ 123 SignalName "comment text";
        
        comment_patterns = [
            (r'CM_\s+BU_\s+(\w+)\s+"([^"]*)"\s*;', 'node'),
            (r'CM_\s+BO_\s+(\d+)\s+"([^"]*)"\s*;', 'message'),
            (r'CM_\s+SG_\s+(\d+)\s+(\w+)\s+"([^"]*)"\s*;', 'signal'),
            (r'CM_\s+"([^"]*)"\s*;', 'general')
        ]
        
        for pattern, comment_type in comment_patterns:
            for match in re.finditer(pattern, content, re.MULTILINE):
                if comment_type == 'node':
                    node_name = match.group(1)
                    comment = match.group(2)
                    for node in self.nodes:
                        if node.name == node_name:
                            node.comment = comment
                            break
                elif comment_type == 'message':
                    can_id_raw = int(match.group(1))
                    can_id, _ = self._convert_raw_can_id(can_id_raw)
                    comment = match.group(2)
                    for message in self.messages:
                        if message.can_id == can_id:
                            message.comment = comment
                            break
                elif comment_type == 'signal':
                    can_id_raw = int(match.group(1))
                    can_id, _ = self._convert_raw_can_id(can_id_raw)
                    signal_name = match.group(2)
                    comment = match.group(3)
                    for message in self.messages:
                        if message.can_id == can_id:
                            for signal in message.signals:
                                if signal.name == signal_name:
                                    signal.comment = comment
                                    break
                            break
    
    def _parse_attributes(self, content: str):
        """è§£æå±æ€§å®šä¹‰"""
        # BA_ "GenMsgCycleTime" BO_ 123 1000;
        attr_pattern = r'BA_\s+"([^"]+)"\s+BO_\s+(\d+)\s+([^;]+);'
        
        for match in re.finditer(attr_pattern, content, re.MULTILINE):
            attr_name = match.group(1)
            can_id_raw = int(match.group(2))
            can_id, _ = self._convert_raw_can_id(can_id_raw)
            attr_value = match.group(3).strip()
            
            if attr_name == "GenMsgCycleTime":
                # è®¾ç½®æ¶ˆæ¯å‘¨æœŸæ—¶é—´
                for message in self.messages:
                    if message.can_id == can_id:
                        try:
                            message.cycle_time = int(attr_value)
                        except ValueError:
                            pass
                        break
    
    def get_message_by_id(self, can_id: int) -> Optional[DBCMessage]:
        """æ ¹æ®CAN IDè·å–æ¶ˆæ¯å®šä¹‰"""
        for message in self.messages:
            if message.can_id == can_id:
                return message
        return None
    
    def get_signals_by_message_id(self, can_id: int) -> List[DBCSignal]:
        """æ ¹æ®CAN IDè·å–ä¿¡å·åˆ—è¡¨"""
        message = self.get_message_by_id(can_id)
        return message.signals if message else []
    
    def search_signals_by_name(self, name_pattern: str) -> List[tuple]:
        """æ ¹æ®åç§°æ¨¡å¼æœç´¢ä¿¡å·"""
        results = []
        pattern = re.compile(name_pattern, re.IGNORECASE)
        
        for message in self.messages:
            for signal in message.signals:
                if pattern.search(signal.name):
                    results.append((message, signal))
        
        return results
    
    def export_signal_list(self) -> List[Dict[str, Any]]:
        """å¯¼å‡ºä¿¡å·åˆ—è¡¨ï¼ˆç”¨äºç•Œé¢æ˜¾ç¤ºï¼‰"""
        signal_list = []
        
        for message in self.messages:
            for signal in message.signals:
                signal_info = {
                    'message_name': message.name,
                    'can_id': message.can_id,
                    'can_id_hex': f"0x{message.can_id:X}",
                    'is_extended': message.is_extended,
                    'signal_name': signal.name,
                    'start_bit': signal.start_bit,
                    'length': signal.length,
                    'byte_order': signal.byte_order,
                    'value_type': signal.value_type,
                    'factor': signal.factor,
                    'offset': signal.offset,
                    'minimum': signal.minimum,
                    'maximum': signal.maximum,
                    'unit': signal.unit,
                    'comment': signal.comment,
                    'cycle_time': message.cycle_time
                }
                signal_list.append(signal_info)
        
        return signal_list

def demo_dbc_parser():
    """DBCè§£æå™¨æ¼”ç¤º"""
    print("ğŸ¯ DBCæ–‡ä»¶è§£ææ¼”ç¤º")
    print("="*50)
    
    # åˆ›å»ºè§£æå™¨
    parser = DBCParser()
    
    # è¿™é‡Œéœ€è¦ä¸€ä¸ªå®é™…çš„DBCæ–‡ä»¶è·¯å¾„
    dbc_file = "example.dbc"
    
    if os.path.exists(dbc_file):
        # è§£ææ–‡ä»¶
        if parser.parse_file(dbc_file):
            # æ˜¾ç¤ºè§£æç»“æœ
            print(f"\nğŸ“Š è§£æç»“æœ:")
            print(f"   èŠ‚ç‚¹æ•°: {len(parser.nodes)}")
            print(f"   æ¶ˆæ¯æ•°: {len(parser.messages)}")
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªæ¶ˆæ¯
            print(f"\nğŸ“‹ æ¶ˆæ¯åˆ—è¡¨:")
            for i, msg in enumerate(parser.messages[:5]):
                ext_flag = " (æ‰©å±•å¸§)" if msg.is_extended else ""
                print(f"   {i+1}. {msg.name} (0x{msg.can_id:X}{ext_flag}) - {len(msg.signals)}ä¸ªä¿¡å·")
                for signal in msg.signals[:3]:  # æ˜¾ç¤ºå‰3ä¸ªä¿¡å·
                    print(f"      â€¢ {signal.name}: {signal.start_bit}ä½, {signal.length}ä½é•¿")
            
            # æœç´¢ç¤ºä¾‹
            search_results = parser.search_signals_by_name("speed")
            print(f"\nğŸ” æœç´¢'speed'ç›¸å…³ä¿¡å·: {len(search_results)}ä¸ªç»“æœ")
            
            # å¯¼å‡ºä¿¡å·åˆ—è¡¨
            signal_list = parser.export_signal_list()
            print(f"\nğŸ“¤ å¯¼å‡ºä¿¡å·åˆ—è¡¨: {len(signal_list)}ä¸ªä¿¡å·")
        
    else:
        print(f"âŒ DBCæ–‡ä»¶ä¸å­˜åœ¨: {dbc_file}")
        print("ğŸ’¡ è¯·æä¾›ä¸€ä¸ªæœ‰æ•ˆçš„DBCæ–‡ä»¶è·¯å¾„è¿›è¡Œæµ‹è¯•")

if __name__ == "__main__":
    demo_dbc_parser()